@article{Arulkumaran2017,
abstract = {Deep reinforcement learning is poised to revolutionise the field of AI and represents a step towards building autonomous systems with a higher level understanding of the visual world. Currently, deep learning is enabling reinforcement learning to scale to problems that were previously intractable, such as learning to play video games directly from pixels. Deep reinforcement learning algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of reinforcement learning, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep reinforcement learning, including the deep {\$}Q{\$}-network, trust region policy optimisation, and asynchronous advantage actor-critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via reinforcement learning. To conclude, we describe several current areas of research within the field.},
archivePrefix = {arXiv},
arxivId = {1708.05866},
author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
doi = {10.1109/MSP.2017.2743240},
eprint = {1708.05866},
isbn = {9781424469178},
issn = {1701.07274},
journal = {IEEE Signal Processing Magazine Special Issue on Deep Learning for Image Understanding},
pages = {1--14},
pmid = {25719670},
title = {{A Brief Survey of Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1708.05866{\%}0Ahttp://dx.doi.org/10.1109/MSP.2017.2743240},
year = {2017}
}
@article{Beattie2016,
abstract = {DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community.},
archivePrefix = {arXiv},
arxivId = {1612.03801},
author = {Beattie, Charles and Leibo, Joel Z. and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and K{\"{u}}ttler, Heinrich and Lefrancq, Andrew and Green, Simon and Vald{\'{e}}s, V{\'{i}}ctor and Sadik, Amir and Schrittwieser, Julian and Anderson, Keith and York, Sarah and Cant, Max and Cain, Adam and Bolton, Adrian and Gaffney, Stephen and King, Helen and Hassabis, Demis and Legg, Shane and Petersen, Stig},
eprint = {1612.03801},
file = {:home/per/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beattie et al. - 2016 - DeepMind Lab.pdf:pdf},
month = {dec},
title = {{DeepMind Lab}},
url = {http://arxiv.org/abs/1612.03801},
year = {2016}
}
@article{Bellemare2012,
abstract = {In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.},
archivePrefix = {arXiv},
arxivId = {1207.4708},
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
doi = {10.1613/jair.3912},
eprint = {1207.4708},
file = {:home/per/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellemare et al. - 2015 - The arcade learning environment An evaluation platform for general agents.pdf:pdf},
isbn = {9781577357384},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {4148--4152},
title = {{The arcade learning environment: An evaluation platform for general agents}},
url = {http://arxiv.org/abs/1207.4708},
volume = {2015-Janua},
year = {2015}
}
